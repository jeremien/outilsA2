  ''"killer robot" redirects here  for articles dealing with the concept of robots and or artificial intelligence killing or eradicating humans and or other living beings  see existential risk from artificial general intelligence  ai takeover  and grey goo '' lethal autonomous weapons  laws  are a type of autonomous military robot designed to select and attack military targets  people  installations  without intervention by a human operator  law are also called lethal autonomous weapon systems  laws   lethal autonomous robots  lar   robotic weapons  or killer robots  laws may operate in the air  on land  on water  under water  or in space  the autonomy of current systems is restricted in the sense that a human gives the final command to attack   though there are exceptions with certain "defensive" systems 

lethal autonomous weapons should not be confused with ucavs or "combat drones"  which are currently remote controlled by human pilots   laws are considered a subset of combat drones   even though combat drones can fly autonomously  they do not fire autonomously  but rather by a trained human operator 

the oldest automatically triggered lethal weapon is the land mine  used since at least the 1600s  and naval mines  used since at least the 1700s  anti personnel mines are banned in many countries by the 1997 ottawa treaty  not including the united states  russia  and much of asia and the middle east  some current examples of laws are automated "hardkill" active protection systems  such as a radar guided gun to defend ships that have been in use since the 1970s  e g  the us phalanx ciws   such systems can autonomously identify and attack oncoming missiles  rockets  artillery fire  aircraft and surface vessels according to criteria set by the human operator  similar systems exist for tanks  such as the russian arena  the israeli trophy  and the german amap ads  several types of stationary sentry guns  which can fire at humans and vehicles  are used in south korea and israel  many missile defense systems  such as iron dome  also have autonomous targeting capabilities  automatic turrets installed on military vehicles are called remote weapon stations  the main reason for not having a "human in the loop" in these systems is the need for rapid response  they have generally been used to protect personnel and installations against incoming projectiles 

systems with a higher degree of autonomy would include drones or unmanned combat aerial vehicles  e g   "the unarmed bae systems taranis jet propelled combat drone prototype may lead to a future offensive air system that can autonomously search  identify and locate enemies but can only engage with a target when authorized by mission command  it can also defend itself against enemy aircraft"  heyns 2013  §45   the northrop grumman x 47b drone can take off and land on aircraft carriers  demonstrated in 2014   it is set to be developed into an unmanned carrier launched airborne surveillance and strike  uclass  system  according to the economist  as technology advances  future applications of unmanned undersea vehicles might include mine clearance  mine laying  anti submarine sensor networking in contested waters  patrolling with active sonar  resupplying manned submarines  and becoming low cost missile platforms  in 2018 the u s  nuclear posture review alleged that russia is developing a "new intercontinental  nuclear armed  nuclear powered  undersea autonomous torpedo" named "status 6"  russian federation is actively developing artificially intelligent missiles  drones  unmanned vehicles  military robots and medic robots  israeli minister ayoub kara stated in 2017 that israel is developing military robots as small as flies in order to assassinate leaders of hezbollah and hamas  and that these robots may be operational within as few as three years 

the possibility of laws has generated significant debate  especially about the risk of "killer robots" roaming the earth   in the near or far future  the group campaign to stop killer robots formed in 2013  in july 2015  over 1 000 experts in artificial intelligence signed a letter warning of the threat of an arms race in military artificial intelligence and calling for a ban on autonomous weapons  the letter was presented in buenos aires at the 24th international joint conference on artificial intelligence  ijcai 15  and was co signed by stephen hawking  elon musk  steve wozniak  noam chomsky  skype co founder jaan tallinn and google deepmind co founder demis hassabis  among others  stuart russell  professor of computer science from university of california  berkeley stated the concern he has with laws is that it is unethical and inhumane  the main issue with this system is it is hard to distinguish between combatants and non combatants  current us policy states  "autonomous … weapons systems shall be designed to allow commanders and operators to exercise appropriate levels of human judgment over the use of force " however  the policy requires that autonomous weapon systems that kill people or use kinetic force  selecting and engaging targets without further human intervention  be certified as compliant with "appropriate levels" and other standards  not that such weapon systems cannot meet these standards and are therefore forbidden  "semi autonomous" hunter killers that autonomously identify and attack targets do not even require certification  deputy defense secretary robert work said in 2016 that the defense department would "not delegate lethal authority to a machine to make a decision"  but might need to reconsider this since "authoritarian regimes" may do so  there is concern  e g  sharkey 2012  about whether laws would violate international humanitarian law  especially the principle of distinction  which requires the ability to discriminate combatants from non combatants  and the principle of proportionality  which requires that damage to civilians is proportional to the military aim  this concern is often invoked as a reason to ban "killer robots" altogether   but it is doubtful that this concern can be an argument against laws that do not violate international humanitarian law  other risks are that  just like with remote controlled drone strikes  laws will make military action easier for some parties  and thus lead to more killings  according to pax fully automated weapons  faws  will lower the threshold of going to war as soldiers are removed from the battlefield and the public is distanced from experiencing war  giving politicians and other decision makers more space in deciding when and how to go to war  they warn that once deployed  faws will make democratic control of war more difficult   something that author of kill decision   a novel on the topic   and it specialist daniel suarez also warned about  according to him it might recentralize power into very few hands by requiring very few people to go to war  finally  laws are said to blur the boundaries of who is responsible for a particular killing  but thomas simpson and vincent müller argue that they may make it easier to record who gave which command  in october 2016 president barack obama stated that early in his career he was wary of a future in which a us president making use of drone warfare could "carry on perpetual wars all over the world  and a lot of them covert  without any accountability or democratic debate" 

  artificial intelligence arms race



